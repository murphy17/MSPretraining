{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/mmurphy/.conda/envs/MSPretraining/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./lightning_logs/carp_pretrained_finetune_hla_a0201/checkpoints/epoch=31-step=448-best.ckpt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 4 required positional arguments: 'model_dim', 'model_depth', 'lr', and 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m [last_ckpt] \u001b[38;5;241m=\u001b[39m get_ipython()\u001b[38;5;241m.\u001b[39mgetoutput(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mls -t1 ./lightning_logs/*/checkpoints/*.ckpt | head -n1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(last_ckpt)\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMSTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_ckpt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m dm \u001b[38;5;241m=\u001b[39m MSDataModule(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m.\u001b[39mhparams))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# dm.prefetch = False\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/MSPretraining/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:161\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# override the hparams with values that were passed in\u001b[39;00m\n\u001b[1;32m    159\u001b[0m checkpoint[\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mCHECKPOINT_HYPER_PARAMS_KEY]\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 161\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.conda/envs/MSPretraining/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:203\u001b[0m, in \u001b[0;36mModelIO._load_model_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cls_spec\u001b[38;5;241m.\u001b[39mvarkw:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     _cls_kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _cls_kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m cls_init_args_name}\n\u001b[0;32m--> 203\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_cls_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# give model a chance to load something\u001b[39;00m\n\u001b[1;32m    206\u001b[0m model\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 4 required positional arguments: 'model_dim', 'model_depth', 'lr', and 'dropout'"
     ]
    }
   ],
   "source": [
    "from src.datamodule import MSDataModule\n",
    "from src.model import MSTransformer\n",
    "\n",
    "[last_ckpt] = !ls -t1 ./lightning_logs/*/checkpoints/*.ckpt | head -n1\n",
    "print(last_ckpt)\n",
    "\n",
    "model = MSTransformer.load_from_checkpoint(last_ckpt)\n",
    "dm = MSDataModule(**dict(model.hparams))\n",
    "\n",
    "# dm.prefetch = False\n",
    "\n",
    "dm.setup()\n",
    "# model = model.cpu()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm.train_dataset), len(dm.val_dataset), len(dm.test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is accuracy per AA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "embeddings = []\n",
    "sequences = []\n",
    "charges = []\n",
    "ces = []\n",
    "spectra = []\n",
    "\n",
    "# fraction of detected peaks?\n",
    "# fraction of b versus y?\n",
    "# entropy?\n",
    "# ...charge?\n",
    "\n",
    "for i, batch in tqdm(enumerate(dm.val_dataloader())):\n",
    "    x = batch['x'].to(model.device)\n",
    "    x_mask = batch['x_mask'].to(model.device).unsqueeze(-1)\n",
    "    z = model.x_encoder(x, x_mask)\n",
    "    z = (z * x_mask).sum(1) / x_mask.sum(1)\n",
    "    z = z.detach().cpu().numpy()\n",
    "    embeddings.append(z)\n",
    "    \n",
    "#     y = batch['y'].cpu().numpy()\n",
    "#     y_mask = batch['y_mask'].cpu().numpy()\n",
    "    \n",
    "#     spectra += [y_i[m_i.sum((1,2,3))>0] for y_i, m_i in zip(y, y_mask)]\n",
    "#     charges.append(batch['charge'].cpu().numpy())\n",
    "#     ces.append(batch['collision_energy'].cpu().numpy())\n",
    "    sequences += batch['sequence']\n",
    "\n",
    "embeddings = np.concatenate(embeddings,0)\n",
    "# charges = np.concatenate(charges,0)\n",
    "# ces = np.concatenate(ces,0)\n",
    "\n",
    "embeddings = pd.DataFrame(embeddings)\n",
    "embeddings = embeddings.groupby(sequences).mean()\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(sequence):\n",
    "    is_basic = np.array([aa in 'RHK' for aa in sequence])\n",
    "    polarity = (is_basic * np.arange(len(sequence))).sum() / np.arange(len(sequence)).sum()\n",
    "    return polarity\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "adata = sc.AnnData(embeddings)\n",
    "\n",
    "adata.obs['sequence'] = embeddings.index\n",
    "adata.obs['length'] = adata.obs['sequence'].map(len)\n",
    "adata.obs['first_aa'] = adata.obs['sequence'].str[0]\n",
    "adata.obs['second_aa'] = adata.obs['sequence'].str[1]\n",
    "adata.obs['last_aa'] = adata.obs['sequence'].str[-1]\n",
    "adata.obs['num_basic'] = adata.obs['sequence'].map(lambda s: sum([c in 'RKH' for c in s])).astype(str)\n",
    "adata.obs['polarity'] = adata.obs['sequence'].map(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import entropy\n",
    "# adata.obs['peak_entropy'] = [entropy(s.ravel())/s.shape[0] for s in spectra]\n",
    "# adata.obs['bond_entropy'] = [entropy(s.sum((1,2,3)).ravel())/s.shape[0] for s in spectra]\n",
    "# adata.obs['terminality'] = [s.sum((0,2,3))[-1]/s.sum() for s in spectra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sc.pp.subsample(adata,fraction=0.25)\n",
    "\n",
    "# from src.cdhit import CDHIT\n",
    "\n",
    "# clusters = CDHIT(threshold=0.9, word_length=5).fit_predict(adata.obs['sequence'])\n",
    "\n",
    "# adata = adata[adata.obs[[]].groupby(clusters).head(3).index]\n",
    "\n",
    "len(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, random_state=0)\n",
    "sc.pp.neighbors(adata, random_state=0)\n",
    "sc.tl.umap(adata, random_state=0)\n",
    "sc.tl.leiden(adata, resolution=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata,color=['length','num_basic'])\n",
    "sc.pl.umap(adata,color=['first_aa','last_aa'])\n",
    "# sc.pl.umap(adata,color=['bond_entropy','terminality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do sequences within sequence-similarity clusters tend to be closer in fragment space? (IOW: \"do distances in 'fragmentation space' have anything to do with edit distance?\")\n",
    "\n",
    "The more interesting question is the other way around. \"Do sequences nearby in fragment space tend to be similar?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.cdhit import CDHIT\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# cdhit = CDHIT(\n",
    "#     threshold=0.9,\n",
    "#     word_length=5\n",
    "# )\n",
    "# clusters = np.array(cdhit.fit_predict(sequences))\n",
    "\n",
    "# X = embeddings.values.copy()\n",
    "\n",
    "# mean_dists = []\n",
    "# for i, c in enumerate(clusters):\n",
    "#     dists = pairwise_distances(X[clusters==c], X[[i]])\n",
    "#     dists = sorted(dists.ravel())[1:]\n",
    "#     if len(dists)==0:\n",
    "#         continue\n",
    "#     mean_dists.append(np.mean(dists))\n",
    "    \n",
    "# npr.seed(0)\n",
    "# X = X[npr.permutation(X.shape[0])]\n",
    "\n",
    "# rand_dists = []\n",
    "# for i, c in enumerate(clusters):\n",
    "#     dists = pairwise_distances(X[clusters==c], X[[i]])\n",
    "#     dists = sorted(dists.ravel())[1:]\n",
    "#     if len(dists)==0:\n",
    "#         continue\n",
    "#     rand_dists.append(np.mean(dists))\n",
    "    \n",
    "# plt.hist([mean_dists,rand_dists],bins=50,histtype='step');\n",
    "\n",
    "# If I rank all other sequences by distance to this one, what's the average rank of other sequences in the same CDHIT cluster? Is it any different than if clusters were assigned randomly?\n",
    "\n",
    "# X = embeddings.values.copy()\n",
    "\n",
    "# npr.seed(0)\n",
    "\n",
    "# from collections import Counter\n",
    "# cluster_counts = Counter(clusters)\n",
    "\n",
    "# mean_ranks = []\n",
    "# rand_ranks = []\n",
    "# for i, c in tqdm(enumerate(clusters)):\n",
    "#     if cluster_counts[c]==1:\n",
    "#         continue\n",
    "#     dists = pairwise_distances(X, X[[i]]).ravel()\n",
    "#     dists[i] = np.inf\n",
    "#     ranks = np.argsort(dists)*1.\n",
    "#     ranks[-1] = np.nan\n",
    "#     mean_ranks.append(np.nanmean(ranks[clusters==c]))\n",
    "#     rand_ranks.append(np.nanmean(ranks[clusters[npr.permutation(len(clusters))]==c]))\n",
    "    \n",
    "# plt.hist([mean_ranks,rand_ranks],bins=50,histtype='step');\n",
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# sns.violinplot(\n",
    "#     data=adata.obs,\n",
    "#     x='leiden',\n",
    "#     y='length',\n",
    "#     order=adata.obs.groupby('leiden')['length'].mean().sort_values().index\n",
    "# )\n",
    "\n",
    "# adata = adata[adata.obs['length']==11]\n",
    "\n",
    "# sc.tl.pca(adata, random_state=0)\n",
    "# sc.pp.neighbors(adata, random_state=0)\n",
    "# sc.tl.umap(adata, random_state=0)\n",
    "# sc.tl.leiden(adata,resolution=0.25, random_state=0)\n",
    "\n",
    "# adata.obs['pc1'] = adata.obsm['X_pca'][:,0]\n",
    "# adata.obs['pc2'] = adata.obsm['X_pca'][:,1]\n",
    "\n",
    "# adata\n",
    "\n",
    "# sc.pl.umap(adata,color=['leiden','bond_entropy','num_basic'])\n",
    "# # sc.pl.umap(adata,color=['first_aa','second_aa'])\n",
    "# # sc.pl.umap(adata,color=['pc1','pc2'])\n",
    "\n",
    "# Polarity still dominates.\n",
    "\n",
    "# def plot_cluster(cluster, ax, vmax):\n",
    "#     df = pd.DataFrame(adata.obs.query(f'leiden==\"{cluster}\"')['sequence'].str.split('').tolist()).iloc[:,1:-1]\n",
    "#     df = df.apply(lambda c: c.value_counts())\n",
    "#     df = df.join(pd.Series({aa:0 for aa in model.residues[1:]},name='aa'),how='outer').drop(columns=['aa']).drop(index=['C','O'])\n",
    "#     df = df.fillna(0).astype(int)\n",
    "#     df.columns.name = 'position'\n",
    "#     plt.sca(ax)\n",
    "#     sns.heatmap(df,vmin=0,vmax=vmax,cmap='Reds')\n",
    "#     plt.title(f'cluster {cluster}')\n",
    "\n",
    "# fig,axs = plt.subplots(1,2,figsize=(16,6))\n",
    "# plot_cluster(3, axs[0], 50)\n",
    "# plot_cluster(7, axs[1], 50)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-MSPretraining]",
   "language": "python",
   "name": "conda-env-.conda-MSPretraining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
