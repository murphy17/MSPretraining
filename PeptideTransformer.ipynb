{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/mmurphy/.conda/envs/MSPretraining/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from src.cdhit import CDHIT, cdhit_split\n",
    "from src.constants import MSConstants\n",
    "from src.torch_helpers import zero_padding_collate, NamedTensorDataset\n",
    "from src.model import PositionalEncoding\n",
    "from sklearn.model_selection import train_test_split\n",
    "C = MSConstants()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeptideDataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df, \n",
    "        batch_size,\n",
    "        train_val_split,\n",
    "        cdhit_threshold,\n",
    "        cdhit_word_length,\n",
    "        num_workers=1,\n",
    "        random_state=0\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.train_val_split = train_val_split\n",
    "        self.cdhit_threshold = cdhit_threshold\n",
    "        self.cdhit_word_length = cdhit_word_length\n",
    "        self.num_workers = num_workers\n",
    "        self.random_state = 0\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.sequences = df['sequence'].tolist()\n",
    "        \n",
    "        self.dataset = NamedTensorDataset(\n",
    "            sequence=df['sequence'],\n",
    "            x=df['sequence'].map(lambda s: np.array([C.alphabet.index(c) for c in s])),\n",
    "            x_mask=df['sequence'].map(lambda s: np.array([1 for c in s])),\n",
    "            y=df.iloc[:,1:].fillna(0).values,  #?#?#???#@$?#?@ ?#$??@!??$ ?%#\n",
    "            y_mask=~np.isnan(df.iloc[:,1:].values)\n",
    "        )\n",
    "        \n",
    "        train_seqs, val_seqs, train_idxs, val_idxs = cdhit_split(\n",
    "            self.sequences,\n",
    "            range(len(self.sequences)),\n",
    "            split=self.train_val_split,\n",
    "            threshold=self.cdhit_threshold,\n",
    "            word_length=self.cdhit_word_length,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        self.train_dataset = Subset(self.dataset, train_idxs)\n",
    "        self.val_dataset = Subset(self.dataset, val_idxs)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        dataloader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            collate_fn=zero_padding_collate,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataloader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            collate_fn=zero_padding_collate,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            drop_last=False\n",
    "        )\n",
    "        return dataloader\n",
    "    \n",
    "    def predict_dataloader(self, shuffle=False):\n",
    "        dataloader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=1,\n",
    "            collate_fn=zero_padding_collate,\n",
    "            num_workers=1,\n",
    "            shuffle=shuffle,\n",
    "            drop_last=False\n",
    "        )\n",
    "        return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dbaasp.csv')#[['sequence','Escherichia coli']].dropna()\n",
    "output_dim = df.shape[1]-1\n",
    "\n",
    "dm = PeptideDataModule(\n",
    "    df,\n",
    "    batch_size=64,\n",
    "    train_val_split=0.8,\n",
    "    cdhit_threshold=0.5,\n",
    "    cdhit_word_length=3,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.torch_helpers import start_tensorboard\n",
    "\n",
    "# start_tensorboard(login_node='login-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "class PeptideTransformer(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        residues,\n",
    "        output_dim,\n",
    "        model_dim,\n",
    "        model_depth,\n",
    "        num_heads,\n",
    "        lr,\n",
    "        dropout,\n",
    "        max_length,\n",
    "        encoder_weights=None,\n",
    "        residue_weights=None,\n",
    "        train_encoder=True,\n",
    "        train_residues=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.residues = residues\n",
    "        self.model_dim = model_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.max_length = max_length\n",
    "        self.model_depth = model_depth\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.lr = lr\n",
    "        self.train_encoder = train_encoder\n",
    "        self.train_residues = train_residues\n",
    "        \n",
    "        self.residue_embedding = nn.Embedding(\n",
    "            len(self.residues)+1, \n",
    "            model_dim,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            d_model=model_dim,\n",
    "            max_len=2*max_length, # striding\n",
    "            dropout=dropout\n",
    "        ).requires_grad_(False)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=model_dim,\n",
    "            nhead=num_heads, \n",
    "            num_encoder_layers=model_depth, \n",
    "            num_decoder_layers=model_depth,\n",
    "            dim_feedforward=model_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer.decoder = None\n",
    "        \n",
    "        clf_layers = []\n",
    "        for i in range(model_depth-1):\n",
    "            clf_layers.append(nn.Linear(model_dim, model_dim))\n",
    "            clf_layers.append(nn.ReLU(inplace=True))\n",
    "            clf_layers.append(nn.BatchNorm1d(model_dim))\n",
    "        clf_layers.append(nn.Linear(model_dim,output_dim))\n",
    "        self.classifier = nn.Sequential(*clf_layers)\n",
    "\n",
    "#         self.classifier = nn.Linear(model_dim, output_dim)\n",
    "        \n",
    "        if residue_weights is not None:\n",
    "            self.residue_embedding.load_state_dict(residue_weights)\n",
    "        if encoder_weights is not None:\n",
    "            self.transformer.encoder.load_state_dict(encoder_weights)\n",
    "            \n",
    "        self.residue_embedding.requires_grad_(train_residues)\n",
    "        self.transformer.encoder.requires_grad_(train_encoder)\n",
    "            \n",
    "    def _encode_src(self, sequence, sequence_mask):\n",
    "        batch_size, max_residues = sequence.shape\n",
    "        # prepend CLS token\n",
    "        cls_token = len(self.residues) * torch.ones_like(sequence[:,[0]])\n",
    "        x = torch.cat([cls_token,sequence],axis=1)\n",
    "        x_mask = torch.cat([cls_token.bool(),sequence_mask],axis=1)\n",
    "        x = self.residue_embedding(x)\n",
    "        x[:,1:] = self.positional_encoding(x[:,1:], offset=0, stride=2)\n",
    "        return x, x_mask\n",
    "    \n",
    "    def forward(self, sequence, sequence_mask):\n",
    "        batch_size, max_residues = sequence.shape\n",
    "        max_bonds = max_residues - 1\n",
    "        \n",
    "        x_src, x_src_mask = model._encode_src(sequence, sequence_mask)\n",
    "        \n",
    "        z = self.transformer.encoder(\n",
    "            src = x_src,\n",
    "            src_key_padding_mask = ~x_src_mask,\n",
    "        )\n",
    "        # cls token\n",
    "        z = z[:,0]\n",
    "        \n",
    "        y_pred = self.classifier(z)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def step(self, batch, predict_step=False):\n",
    "        batch_size = batch['x'].shape[0]\n",
    "\n",
    "        y = batch['y'].float()\n",
    "        y_mask = batch['y_mask'].bool()\n",
    "        \n",
    "        y_pred = self(\n",
    "            sequence=batch['x'].long(),\n",
    "            sequence_mask=batch['x_mask'].bool()\n",
    "        )\n",
    "        \n",
    "        if predict_step:\n",
    "            return y_pred\n",
    "\n",
    "        # probably gonna have to mask here too\n",
    "        loss = ((y_pred - y).square() * y_mask).sum() / y_mask.sum()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_size = batch['x'].shape[0]\n",
    "        loss = self.step(batch)\n",
    "        assert not torch.isnan(loss).any().item(), batch_idx\n",
    "        self.log('train_mse',loss,batch_size=batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch_size = batch['x'].shape[0]\n",
    "        loss = self.step(batch)\n",
    "        self.log('valid_mse',loss,batch_size=batch_size,sync_dist=True)\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx=None):\n",
    "        return self.step(batch, predict_step=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just show that init'ing from weights trained on MS gives better val err..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAIN = True\n",
    "\n",
    "if PRETRAIN:\n",
    "    [last_ckpt] = !ls -t1 ./lightning_logs/version_15649130/checkpoints/*.ckpt | head -n1\n",
    "    #pretrained_checkpoint = './lightning_logs/version_15655593/checkpoints/epoch=37-step=24927.ckpt'\n",
    "    pretrained_checkpoint = last_ckpt\n",
    "    state_dict = torch.load(pretrained_checkpoint,map_location=torch.device('cpu'))['state_dict']\n",
    "\n",
    "    name = 'residue_embedding'\n",
    "    residue_weights = {k.replace(name+'.',''):v for k,v in state_dict.items() if k.startswith(name)}\n",
    "    \n",
    "    name = 'transformer.encoder'\n",
    "    encoder_weights = {k.replace(name+'.',''):v for k,v in state_dict.items() if k.startswith(name)}\n",
    "else:\n",
    "    residue_weights = encoder_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = PeptideTransformer(\n",
    "    residues=C.alphabet,\n",
    "    model_dim=512,\n",
    "    output_dim=output_dim,\n",
    "    model_depth=4,\n",
    "    num_heads=4,\n",
    "    lr=1e-4,\n",
    "    dropout=0.1,\n",
    "    max_length=100,\n",
    "    residue_weights=residue_weights,\n",
    "    encoder_weights=encoder_weights,\n",
    "    train_encoder=False,\n",
    "    train_residues=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# !rm -rf ./lightning_logs/`ls -t ./lightning_logs | head -n1`\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    max_epochs=100,\n",
    "    precision=32,\n",
    "    log_every_n_steps=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | residue_embedding   | Embedding          | 12.8 K\n",
      "1 | positional_encoding | PositionalEncoding | 0     \n",
      "2 | transformer         | Transformer        | 6.3 M \n",
      "3 | classifier          | Linear             | 2.6 K \n",
      "-----------------------------------------------------------\n",
      "2.6 K     Trainable params\n",
      "6.3 M     Non-trainable params\n",
      "6.3 M     Total params\n",
      "25.313    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  78%|███████▊  | 32/41 [00:01<00:00, 17.47it/s, loss=5.23, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 34/41 [00:02<00:00, 15.12it/s, loss=5.23, v_num=1.57e+7]\n",
      "Epoch 0:  90%|█████████ | 37/41 [00:02<00:00, 15.41it/s, loss=5.23, v_num=1.57e+7]\n",
      "Epoch 0: 100%|██████████| 41/41 [00:02<00:00, 15.92it/s, loss=5.23, v_num=1.57e+7]\n",
      "Epoch 1:  80%|████████  | 33/41 [00:01<00:00, 16.54it/s, loss=3.95, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.57it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 36/41 [00:02<00:00, 14.85it/s, loss=3.95, v_num=1.57e+7]\n",
      "Epoch 1:  95%|█████████▌| 39/41 [00:02<00:00, 15.43it/s, loss=3.95, v_num=1.57e+7]\n",
      "Epoch 1: 100%|██████████| 41/41 [00:02<00:00, 15.24it/s, loss=3.95, v_num=1.57e+7]\n",
      "Epoch 2:  80%|████████  | 33/41 [00:01<00:00, 17.87it/s, loss=3.43, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.61it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 36/41 [00:02<00:00, 15.96it/s, loss=3.43, v_num=1.57e+7]\n",
      "Epoch 2: 100%|██████████| 41/41 [00:02<00:00, 16.82it/s, loss=3.43, v_num=1.57e+7]\n",
      "Epoch 3:  78%|███████▊  | 32/41 [00:01<00:00, 16.93it/s, loss=3.08, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.62it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 36/41 [00:02<00:00, 15.44it/s, loss=3.08, v_num=1.57e+7]\n",
      "Epoch 3:  98%|█████████▊| 40/41 [00:02<00:00, 16.03it/s, loss=3.08, v_num=1.57e+7]\n",
      "Epoch 3: 100%|██████████| 41/41 [00:02<00:00, 15.98it/s, loss=3.08, v_num=1.57e+7]\n",
      "Epoch 4:  78%|███████▊  | 32/41 [00:01<00:00, 17.31it/s, loss=2.85, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.21it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 36/41 [00:02<00:00, 15.64it/s, loss=2.85, v_num=1.57e+7]\n",
      "Epoch 4:  98%|█████████▊| 40/41 [00:02<00:00, 16.36it/s, loss=2.85, v_num=1.57e+7]\n",
      "Epoch 4: 100%|██████████| 41/41 [00:02<00:00, 16.30it/s, loss=2.85, v_num=1.57e+7]\n",
      "Epoch 5:  78%|███████▊  | 32/41 [00:01<00:00, 17.76it/s, loss=3.17, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.28it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 36/41 [00:02<00:00, 15.85it/s, loss=3.17, v_num=1.57e+7]\n",
      "Epoch 5: 100%|██████████| 41/41 [00:02<00:00, 16.50it/s, loss=3.17, v_num=1.57e+7]\n",
      "Epoch 6:  78%|███████▊  | 32/41 [00:01<00:00, 19.77it/s, loss=2.7, v_num=1.57e+7] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.45it/s]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 36/41 [00:02<00:00, 17.61it/s, loss=2.7, v_num=1.57e+7]\n",
      "Epoch 6:  98%|█████████▊| 40/41 [00:02<00:00, 18.24it/s, loss=2.7, v_num=1.57e+7]\n",
      "Epoch 6: 100%|██████████| 41/41 [00:02<00:00, 18.14it/s, loss=2.7, v_num=1.57e+7]\n",
      "Epoch 7:  78%|███████▊  | 32/41 [00:01<00:00, 17.84it/s, loss=2.86, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.27it/s]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 36/41 [00:02<00:00, 15.82it/s, loss=2.86, v_num=1.57e+7]\n",
      "Epoch 7:  98%|█████████▊| 40/41 [00:02<00:00, 16.53it/s, loss=2.86, v_num=1.57e+7]\n",
      "Epoch 7: 100%|██████████| 41/41 [00:02<00:00, 16.36it/s, loss=2.86, v_num=1.57e+7]\n",
      "Epoch 8:  78%|███████▊  | 32/41 [00:01<00:00, 19.31it/s, loss=2.88, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.15it/s]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 36/41 [00:02<00:00, 17.08it/s, loss=2.88, v_num=1.57e+7]\n",
      "Epoch 8:  98%|█████████▊| 40/41 [00:02<00:00, 17.73it/s, loss=2.88, v_num=1.57e+7]\n",
      "Epoch 8: 100%|██████████| 41/41 [00:02<00:00, 17.66it/s, loss=2.88, v_num=1.57e+7]\n",
      "Epoch 9:  78%|███████▊  | 32/41 [00:01<00:00, 19.57it/s, loss=2.59, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.62it/s]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 36/41 [00:02<00:00, 17.55it/s, loss=2.59, v_num=1.57e+7]\n",
      "Epoch 9: 100%|██████████| 41/41 [00:02<00:00, 18.19it/s, loss=2.59, v_num=1.57e+7]\n",
      "Epoch 10:  78%|███████▊  | 32/41 [00:01<00:00, 17.75it/s, loss=2.59, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.28it/s]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 36/41 [00:02<00:00, 15.79it/s, loss=2.59, v_num=1.57e+7]\n",
      "Epoch 10:  98%|█████████▊| 40/41 [00:02<00:00, 16.48it/s, loss=2.59, v_num=1.57e+7]\n",
      "Epoch 10: 100%|██████████| 41/41 [00:02<00:00, 16.44it/s, loss=2.59, v_num=1.57e+7]\n",
      "Epoch 11:  78%|███████▊  | 32/41 [00:01<00:00, 18.67it/s, loss=2.57, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.32it/s]\u001b[A\n",
      "Epoch 11:  88%|████████▊ | 36/41 [00:02<00:00, 16.65it/s, loss=2.57, v_num=1.57e+7]\n",
      "Epoch 11:  98%|█████████▊| 40/41 [00:02<00:00, 17.35it/s, loss=2.57, v_num=1.57e+7]\n",
      "Epoch 11: 100%|██████████| 41/41 [00:02<00:00, 17.25it/s, loss=2.57, v_num=1.57e+7]\n",
      "Epoch 12:  78%|███████▊  | 32/41 [00:01<00:00, 19.40it/s, loss=2.63, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.77it/s]\u001b[A\n",
      "Epoch 12:  88%|████████▊ | 36/41 [00:02<00:00, 17.40it/s, loss=2.63, v_num=1.57e+7]\n",
      "Epoch 12:  98%|█████████▊| 40/41 [00:02<00:00, 18.07it/s, loss=2.63, v_num=1.57e+7]\n",
      "Epoch 12: 100%|██████████| 41/41 [00:02<00:00, 17.92it/s, loss=2.63, v_num=1.57e+7]\n",
      "Epoch 13:  78%|███████▊  | 32/41 [00:01<00:00, 20.33it/s, loss=2.45, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.47it/s]\u001b[A\n",
      "Epoch 13:  88%|████████▊ | 36/41 [00:02<00:00, 17.97it/s, loss=2.45, v_num=1.57e+7]\n",
      "Epoch 13: 100%|██████████| 41/41 [00:02<00:00, 18.53it/s, loss=2.45, v_num=1.57e+7]\n",
      "Epoch 14:  78%|███████▊  | 32/41 [00:01<00:00, 18.58it/s, loss=2.37, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.36it/s]\u001b[A\n",
      "Epoch 14:  88%|████████▊ | 36/41 [00:02<00:00, 16.34it/s, loss=2.37, v_num=1.57e+7]\n",
      "Epoch 14: 100%|██████████| 41/41 [00:02<00:00, 17.07it/s, loss=2.37, v_num=1.57e+7]\n",
      "Epoch 15:  78%|███████▊  | 32/41 [00:01<00:00, 18.01it/s, loss=2.42, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.62it/s]\u001b[A\n",
      "Epoch 15:  88%|████████▊ | 36/41 [00:02<00:00, 16.41it/s, loss=2.42, v_num=1.57e+7]\n",
      "Epoch 15:  98%|█████████▊| 40/41 [00:02<00:00, 17.14it/s, loss=2.42, v_num=1.57e+7]\n",
      "Epoch 15: 100%|██████████| 41/41 [00:02<00:00, 17.06it/s, loss=2.42, v_num=1.57e+7]\n",
      "Epoch 16:  78%|███████▊  | 32/41 [00:01<00:00, 18.38it/s, loss=2.49, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.40it/s]\u001b[A\n",
      "Epoch 16:  88%|████████▊ | 36/41 [00:02<00:00, 16.57it/s, loss=2.49, v_num=1.57e+7]\n",
      "Epoch 16:  98%|█████████▊| 40/41 [00:02<00:00, 17.28it/s, loss=2.49, v_num=1.57e+7]\n",
      "Epoch 16: 100%|██████████| 41/41 [00:02<00:00, 17.20it/s, loss=2.49, v_num=1.57e+7]\n",
      "Epoch 17:  78%|███████▊  | 32/41 [00:01<00:00, 18.63it/s, loss=2.43, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.43it/s]\u001b[A\n",
      "Epoch 17:  88%|████████▊ | 36/41 [00:02<00:00, 16.57it/s, loss=2.43, v_num=1.57e+7]\n",
      "Epoch 17:  98%|█████████▊| 40/41 [00:02<00:00, 17.25it/s, loss=2.43, v_num=1.57e+7]\n",
      "Epoch 17: 100%|██████████| 41/41 [00:02<00:00, 17.16it/s, loss=2.43, v_num=1.57e+7]\n",
      "Epoch 18:  78%|███████▊  | 32/41 [00:01<00:00, 18.73it/s, loss=2.31, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.56it/s]\u001b[A\n",
      "Epoch 18:  88%|████████▊ | 36/41 [00:02<00:00, 16.83it/s, loss=2.31, v_num=1.57e+7]\n",
      "Epoch 18: 100%|██████████| 41/41 [00:02<00:00, 17.35it/s, loss=2.31, v_num=1.57e+7]\n",
      "Epoch 19:  78%|███████▊  | 32/41 [00:01<00:00, 17.17it/s, loss=2.37, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.04it/s]\u001b[A\n",
      "Epoch 19:  88%|████████▊ | 36/41 [00:02<00:00, 15.47it/s, loss=2.37, v_num=1.57e+7]\n",
      "Epoch 19:  98%|█████████▊| 40/41 [00:02<00:00, 16.18it/s, loss=2.37, v_num=1.57e+7]\n",
      "Epoch 19: 100%|██████████| 41/41 [00:02<00:00, 16.11it/s, loss=2.37, v_num=1.57e+7]\n",
      "Epoch 20:  78%|███████▊  | 32/41 [00:01<00:00, 18.99it/s, loss=2.4, v_num=1.57e+7] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.11it/s]\u001b[A\n",
      "Epoch 20:  88%|████████▊ | 36/41 [00:02<00:00, 16.76it/s, loss=2.4, v_num=1.57e+7]\n",
      "Epoch 20:  98%|█████████▊| 40/41 [00:02<00:00, 17.48it/s, loss=2.4, v_num=1.57e+7]\n",
      "Epoch 20: 100%|██████████| 41/41 [00:02<00:00, 17.37it/s, loss=2.4, v_num=1.57e+7]\n",
      "Epoch 21:  78%|███████▊  | 32/41 [00:01<00:00, 18.81it/s, loss=2.23, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.19it/s]\u001b[A\n",
      "Epoch 21:  88%|████████▊ | 36/41 [00:02<00:00, 16.62it/s, loss=2.23, v_num=1.57e+7]\n",
      "Epoch 21: 100%|██████████| 41/41 [00:02<00:00, 17.49it/s, loss=2.23, v_num=1.57e+7]\n",
      "Epoch 22:  78%|███████▊  | 32/41 [00:01<00:00, 19.64it/s, loss=2.25, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.46it/s]\u001b[A\n",
      "Epoch 22:  88%|████████▊ | 36/41 [00:02<00:00, 17.52it/s, loss=2.25, v_num=1.57e+7]\n",
      "Epoch 22:  98%|█████████▊| 40/41 [00:02<00:00, 18.16it/s, loss=2.25, v_num=1.57e+7]\n",
      "Epoch 22: 100%|██████████| 41/41 [00:02<00:00, 18.07it/s, loss=2.25, v_num=1.57e+7]\n",
      "Epoch 23:  78%|███████▊  | 32/41 [00:01<00:00, 17.19it/s, loss=2.17, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.08it/s]\u001b[A\n",
      "Epoch 23:  88%|████████▊ | 36/41 [00:02<00:00, 15.33it/s, loss=2.17, v_num=1.57e+7]\n",
      "Epoch 23:  98%|█████████▊| 40/41 [00:02<00:00, 16.01it/s, loss=2.17, v_num=1.57e+7]\n",
      "Epoch 23: 100%|██████████| 41/41 [00:02<00:00, 16.00it/s, loss=2.17, v_num=1.57e+7]\n",
      "Epoch 24:  78%|███████▊  | 32/41 [00:01<00:00, 18.28it/s, loss=2.27, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.20it/s]\u001b[A\n",
      "Epoch 24:  88%|████████▊ | 36/41 [00:02<00:00, 16.45it/s, loss=2.27, v_num=1.57e+7]\n",
      "Epoch 24: 100%|██████████| 41/41 [00:02<00:00, 17.16it/s, loss=2.27, v_num=1.57e+7]\n",
      "Epoch 25:  78%|███████▊  | 32/41 [00:01<00:00, 20.15it/s, loss=2.19, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.43it/s]\u001b[A\n",
      "Epoch 25:  88%|████████▊ | 36/41 [00:02<00:00, 17.62it/s, loss=2.19, v_num=1.57e+7]\n",
      "Epoch 25:  98%|█████████▊| 40/41 [00:02<00:00, 18.25it/s, loss=2.19, v_num=1.57e+7]\n",
      "Epoch 25: 100%|██████████| 41/41 [00:02<00:00, 18.13it/s, loss=2.19, v_num=1.57e+7]\n",
      "Epoch 26:  78%|███████▊  | 32/41 [00:01<00:00, 17.64it/s, loss=2.3, v_num=1.57e+7] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  2.92it/s]\u001b[A\n",
      "Epoch 26:  88%|████████▊ | 36/41 [00:02<00:00, 15.77it/s, loss=2.3, v_num=1.57e+7]\n",
      "Epoch 26:  98%|█████████▊| 40/41 [00:02<00:00, 16.40it/s, loss=2.3, v_num=1.57e+7]\n",
      "Epoch 26: 100%|██████████| 41/41 [00:02<00:00, 16.33it/s, loss=2.3, v_num=1.57e+7]\n",
      "Epoch 27:  78%|███████▊  | 32/41 [00:01<00:00, 18.88it/s, loss=2.27, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.74it/s]\u001b[A\n",
      "Epoch 27:  88%|████████▊ | 36/41 [00:02<00:00, 17.00it/s, loss=2.27, v_num=1.57e+7]\n",
      "Epoch 27:  98%|█████████▊| 40/41 [00:02<00:00, 17.67it/s, loss=2.27, v_num=1.57e+7]\n",
      "Epoch 27: 100%|██████████| 41/41 [00:02<00:00, 17.54it/s, loss=2.27, v_num=1.57e+7]\n",
      "Epoch 28:  78%|███████▊  | 32/41 [00:01<00:00, 18.35it/s, loss=2.22, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.17it/s]\u001b[A\n",
      "Epoch 28:  88%|████████▊ | 36/41 [00:02<00:00, 16.39it/s, loss=2.22, v_num=1.57e+7]\n",
      "Epoch 28:  98%|█████████▊| 40/41 [00:02<00:00, 17.06it/s, loss=2.22, v_num=1.57e+7]\n",
      "Epoch 28: 100%|██████████| 41/41 [00:02<00:00, 17.00it/s, loss=2.22, v_num=1.57e+7]\n",
      "Epoch 29:  78%|███████▊  | 32/41 [00:01<00:00, 19.52it/s, loss=2.21, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  2.96it/s]\u001b[A\n",
      "Epoch 29:  88%|████████▊ | 36/41 [00:02<00:00, 17.11it/s, loss=2.21, v_num=1.57e+7]\n",
      "Epoch 29:  98%|█████████▊| 40/41 [00:02<00:00, 17.83it/s, loss=2.21, v_num=1.57e+7]\n",
      "Epoch 29: 100%|██████████| 41/41 [00:02<00:00, 17.70it/s, loss=2.21, v_num=1.57e+7]\n",
      "Epoch 30:  78%|███████▊  | 32/41 [00:01<00:00, 20.57it/s, loss=2.13, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  2.73it/s]\u001b[A\n",
      "Epoch 30:  88%|████████▊ | 36/41 [00:02<00:00, 17.63it/s, loss=2.13, v_num=1.57e+7]\n",
      "Epoch 30:  98%|█████████▊| 40/41 [00:02<00:00, 18.21it/s, loss=2.13, v_num=1.57e+7]\n",
      "Epoch 30: 100%|██████████| 41/41 [00:02<00:00, 18.09it/s, loss=2.13, v_num=1.57e+7]\n",
      "Epoch 31:  78%|███████▊  | 32/41 [00:01<00:00, 19.86it/s, loss=2.28, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.40it/s]\u001b[A\n",
      "Epoch 31:  88%|████████▊ | 36/41 [00:02<00:00, 17.48it/s, loss=2.28, v_num=1.57e+7]\n",
      "Epoch 31: 100%|██████████| 41/41 [00:02<00:00, 17.88it/s, loss=2.28, v_num=1.57e+7]\n",
      "Epoch 32:  78%|███████▊  | 32/41 [00:01<00:00, 17.92it/s, loss=2.16, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.19it/s]\u001b[A\n",
      "Epoch 32:  88%|████████▊ | 36/41 [00:02<00:00, 15.90it/s, loss=2.16, v_num=1.57e+7]\n",
      "Epoch 32:  98%|█████████▊| 40/41 [00:02<00:00, 16.52it/s, loss=2.16, v_num=1.57e+7]\n",
      "Epoch 32: 100%|██████████| 41/41 [00:02<00:00, 16.46it/s, loss=2.16, v_num=1.57e+7]\n",
      "Epoch 33:  78%|███████▊  | 32/41 [00:01<00:00, 18.25it/s, loss=2.19, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.14it/s]\u001b[A\n",
      "Epoch 33:  88%|████████▊ | 36/41 [00:02<00:00, 16.36it/s, loss=2.19, v_num=1.57e+7]\n",
      "Epoch 33:  98%|█████████▊| 40/41 [00:02<00:00, 17.04it/s, loss=2.19, v_num=1.57e+7]\n",
      "Epoch 33: 100%|██████████| 41/41 [00:02<00:00, 16.94it/s, loss=2.19, v_num=1.57e+7]\n",
      "Epoch 34:  78%|███████▊  | 32/41 [00:01<00:00, 19.46it/s, loss=2.15, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.14it/s]\u001b[A\n",
      "Epoch 34:  88%|████████▊ | 36/41 [00:02<00:00, 17.09it/s, loss=2.15, v_num=1.57e+7]\n",
      "Epoch 34: 100%|██████████| 41/41 [00:02<00:00, 17.55it/s, loss=2.15, v_num=1.57e+7]\n",
      "Epoch 35:  78%|███████▊  | 32/41 [00:01<00:00, 19.70it/s, loss=2.14, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.31it/s]\u001b[A\n",
      "Epoch 35:  88%|████████▊ | 36/41 [00:02<00:00, 17.10it/s, loss=2.14, v_num=1.57e+7]\n",
      "Epoch 35:  98%|█████████▊| 40/41 [00:02<00:00, 17.67it/s, loss=2.14, v_num=1.57e+7]\n",
      "Epoch 35: 100%|██████████| 41/41 [00:02<00:00, 17.59it/s, loss=2.14, v_num=1.57e+7]\n",
      "Epoch 36:  78%|███████▊  | 32/41 [00:01<00:00, 18.18it/s, loss=2.29, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.40it/s]\u001b[A\n",
      "Epoch 36:  88%|████████▊ | 36/41 [00:02<00:00, 16.29it/s, loss=2.29, v_num=1.57e+7]\n",
      "Epoch 36: 100%|██████████| 41/41 [00:02<00:00, 16.96it/s, loss=2.29, v_num=1.57e+7]\n",
      "Epoch 37:  78%|███████▊  | 32/41 [00:01<00:00, 19.33it/s, loss=2.08, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.49it/s]\u001b[A\n",
      "Epoch 37:  88%|████████▊ | 36/41 [00:02<00:00, 17.15it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 37: 100%|██████████| 41/41 [00:02<00:00, 17.80it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 38:  78%|███████▊  | 32/41 [00:01<00:00, 19.87it/s, loss=2.12, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.38it/s]\u001b[A\n",
      "Epoch 38:  88%|████████▊ | 36/41 [00:02<00:00, 17.45it/s, loss=2.12, v_num=1.57e+7]\n",
      "Epoch 38:  98%|█████████▊| 40/41 [00:02<00:00, 18.15it/s, loss=2.12, v_num=1.57e+7]\n",
      "Epoch 38: 100%|██████████| 41/41 [00:02<00:00, 18.01it/s, loss=2.12, v_num=1.57e+7]\n",
      "Epoch 39:  78%|███████▊  | 32/41 [00:01<00:00, 19.49it/s, loss=2.13, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.16it/s]\u001b[A\n",
      "Epoch 39:  88%|████████▊ | 36/41 [00:02<00:00, 17.06it/s, loss=2.13, v_num=1.57e+7]\n",
      "Epoch 39: 100%|██████████| 41/41 [00:02<00:00, 17.77it/s, loss=2.13, v_num=1.57e+7]\n",
      "Epoch 40:  78%|███████▊  | 32/41 [00:01<00:00, 18.43it/s, loss=2.12, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.42it/s]\u001b[A\n",
      "Epoch 40:  88%|████████▊ | 36/41 [00:02<00:00, 16.42it/s, loss=2.12, v_num=1.57e+7]\n",
      "Epoch 40:  98%|█████████▊| 40/41 [00:02<00:00, 17.11it/s, loss=2.12, v_num=1.57e+7]\n",
      "Epoch 40: 100%|██████████| 41/41 [00:02<00:00, 17.04it/s, loss=2.12, v_num=1.57e+7]\n",
      "Epoch 41:  78%|███████▊  | 32/41 [00:01<00:00, 19.04it/s, loss=2.15, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.63it/s]\u001b[A\n",
      "Epoch 41:  88%|████████▊ | 36/41 [00:02<00:00, 16.94it/s, loss=2.15, v_num=1.57e+7]\n",
      "Epoch 41:  98%|█████████▊| 40/41 [00:02<00:00, 17.63it/s, loss=2.15, v_num=1.57e+7]\n",
      "Epoch 41: 100%|██████████| 41/41 [00:02<00:00, 17.44it/s, loss=2.15, v_num=1.57e+7]\n",
      "Epoch 42:  78%|███████▊  | 32/41 [00:01<00:00, 18.78it/s, loss=2.03, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.56it/s]\u001b[A\n",
      "Epoch 42:  88%|████████▊ | 36/41 [00:02<00:00, 16.90it/s, loss=2.03, v_num=1.57e+7]\n",
      "Epoch 42: 100%|██████████| 41/41 [00:02<00:00, 17.63it/s, loss=2.03, v_num=1.57e+7]\n",
      "Epoch 43:  78%|███████▊  | 32/41 [00:01<00:00, 17.87it/s, loss=2.04, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  2.95it/s]\u001b[A\n",
      "Epoch 43:  88%|████████▊ | 36/41 [00:02<00:00, 15.80it/s, loss=2.04, v_num=1.57e+7]\n",
      "Epoch 43:  98%|█████████▊| 40/41 [00:02<00:00, 16.44it/s, loss=2.04, v_num=1.57e+7]\n",
      "Epoch 43: 100%|██████████| 41/41 [00:02<00:00, 16.37it/s, loss=2.04, v_num=1.57e+7]\n",
      "Epoch 44:  78%|███████▊  | 32/41 [00:01<00:00, 18.83it/s, loss=2.24, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.28it/s]\u001b[A\n",
      "Epoch 44:  88%|████████▊ | 36/41 [00:02<00:00, 16.73it/s, loss=2.24, v_num=1.57e+7]\n",
      "Epoch 44: 100%|██████████| 41/41 [00:02<00:00, 17.50it/s, loss=2.24, v_num=1.57e+7]\n",
      "Epoch 45:  78%|███████▊  | 32/41 [00:01<00:00, 17.06it/s, loss=2.15, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.05it/s]\u001b[A\n",
      "Epoch 45:  88%|████████▊ | 36/41 [00:02<00:00, 15.31it/s, loss=2.15, v_num=1.57e+7]\n",
      "Epoch 45:  98%|█████████▊| 40/41 [00:02<00:00, 15.96it/s, loss=2.15, v_num=1.57e+7]\n",
      "Epoch 45: 100%|██████████| 41/41 [00:02<00:00, 15.88it/s, loss=2.15, v_num=1.57e+7]\n",
      "Epoch 46:  78%|███████▊  | 32/41 [00:01<00:00, 16.82it/s, loss=2.07, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.28it/s]\u001b[A\n",
      "Epoch 46:  88%|████████▊ | 36/41 [00:02<00:00, 15.27it/s, loss=2.07, v_num=1.57e+7]\n",
      "Epoch 46:  98%|█████████▊| 40/41 [00:02<00:00, 15.89it/s, loss=2.07, v_num=1.57e+7]\n",
      "Epoch 46: 100%|██████████| 41/41 [00:02<00:00, 15.82it/s, loss=2.07, v_num=1.57e+7]\n",
      "Epoch 47:  78%|███████▊  | 32/41 [00:01<00:00, 17.73it/s, loss=2.03, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.31it/s]\u001b[A\n",
      "Epoch 47:  88%|████████▊ | 36/41 [00:02<00:00, 15.84it/s, loss=2.03, v_num=1.57e+7]\n",
      "Epoch 47:  98%|█████████▊| 40/41 [00:02<00:00, 16.39it/s, loss=2.03, v_num=1.57e+7]\n",
      "Epoch 47: 100%|██████████| 41/41 [00:02<00:00, 16.12it/s, loss=2.03, v_num=1.57e+7]\n",
      "Epoch 48:  78%|███████▊  | 32/41 [00:01<00:00, 18.97it/s, loss=2.05, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.27it/s]\u001b[A\n",
      "Epoch 48:  88%|████████▊ | 36/41 [00:02<00:00, 17.07it/s, loss=2.05, v_num=1.57e+7]\n",
      "Epoch 48:  98%|█████████▊| 40/41 [00:02<00:00, 17.67it/s, loss=2.05, v_num=1.57e+7]\n",
      "Epoch 48: 100%|██████████| 41/41 [00:02<00:00, 17.59it/s, loss=2.05, v_num=1.57e+7]\n",
      "Epoch 49:  78%|███████▊  | 32/41 [00:01<00:00, 17.52it/s, loss=2.08, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.61it/s]\u001b[A\n",
      "Epoch 49:  88%|████████▊ | 36/41 [00:02<00:00, 16.01it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 49: 100%|██████████| 41/41 [00:02<00:00, 16.66it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 50:  78%|███████▊  | 32/41 [00:01<00:00, 18.70it/s, loss=2.08, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.65it/s]\u001b[A\n",
      "Epoch 50:  88%|████████▊ | 36/41 [00:02<00:00, 16.75it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 50:  98%|█████████▊| 40/41 [00:02<00:00, 17.39it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 50: 100%|██████████| 41/41 [00:02<00:00, 17.28it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 51:  78%|███████▊  | 32/41 [00:01<00:00, 18.00it/s, loss=2.09, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.19it/s]\u001b[A\n",
      "Epoch 51:  88%|████████▊ | 36/41 [00:02<00:00, 16.25it/s, loss=2.09, v_num=1.57e+7]\n",
      "Epoch 51: 100%|██████████| 41/41 [00:02<00:00, 16.83it/s, loss=2.09, v_num=1.57e+7]\n",
      "Epoch 52:  78%|███████▊  | 32/41 [00:01<00:00, 17.12it/s, loss=2.13, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.68it/s]\u001b[A\n",
      "Epoch 52:  88%|████████▊ | 36/41 [00:02<00:00, 15.80it/s, loss=2.13, v_num=1.57e+7]\n",
      "Epoch 52:  98%|█████████▊| 40/41 [00:02<00:00, 16.46it/s, loss=2.13, v_num=1.57e+7]\n",
      "Epoch 52: 100%|██████████| 41/41 [00:02<00:00, 16.39it/s, loss=2.13, v_num=1.57e+7]\n",
      "Epoch 53:  78%|███████▊  | 32/41 [00:01<00:00, 17.78it/s, loss=2.08, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.33it/s]\u001b[A\n",
      "Epoch 53:  88%|████████▊ | 36/41 [00:02<00:00, 15.81it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 53:  98%|█████████▊| 40/41 [00:02<00:00, 16.48it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 53: 100%|██████████| 41/41 [00:02<00:00, 16.40it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 54:  78%|███████▊  | 32/41 [00:01<00:00, 18.00it/s, loss=2.08, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.60it/s]\u001b[A\n",
      "Epoch 54:  88%|████████▊ | 36/41 [00:02<00:00, 16.44it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 54:  98%|█████████▊| 40/41 [00:02<00:00, 17.16it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 54: 100%|██████████| 41/41 [00:02<00:00, 17.00it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 55:  78%|███████▊  | 32/41 [00:01<00:00, 18.66it/s, loss=2.08, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.08it/s]\u001b[A\n",
      "Epoch 55:  88%|████████▊ | 36/41 [00:02<00:00, 16.39it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 55:  98%|█████████▊| 40/41 [00:02<00:00, 17.02it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 55: 100%|██████████| 41/41 [00:02<00:00, 16.93it/s, loss=2.08, v_num=1.57e+7]\n",
      "Epoch 56:  78%|███████▊  | 32/41 [00:01<00:00, 19.04it/s, loss=1.96, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.36it/s]\u001b[A\n",
      "Epoch 56:  88%|████████▊ | 36/41 [00:02<00:00, 16.73it/s, loss=1.96, v_num=1.57e+7]\n",
      "Epoch 56:  98%|█████████▊| 40/41 [00:02<00:00, 17.42it/s, loss=1.96, v_num=1.57e+7]\n",
      "Epoch 56: 100%|██████████| 41/41 [00:02<00:00, 17.35it/s, loss=1.96, v_num=1.57e+7]\n",
      "Epoch 57:  78%|███████▊  | 32/41 [00:01<00:00, 17.03it/s, loss=1.97, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.30it/s]\u001b[A\n",
      "Epoch 57:  88%|████████▊ | 36/41 [00:02<00:00, 15.42it/s, loss=1.97, v_num=1.57e+7]\n",
      "Epoch 57:  98%|█████████▊| 40/41 [00:02<00:00, 16.05it/s, loss=1.97, v_num=1.57e+7]\n",
      "Epoch 57: 100%|██████████| 41/41 [00:02<00:00, 16.00it/s, loss=1.97, v_num=1.57e+7]\n",
      "Epoch 58:  78%|███████▊  | 32/41 [00:01<00:00, 17.73it/s, loss=2.03, v_num=1.57e+7]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:  11%|█         | 1/9 [00:00<00:02,  3.12it/s]\u001b[A\n",
      "Epoch 58:  88%|████████▊ | 36/41 [00:02<00:00, 15.59it/s, loss=2.03, v_num=1.57e+7]\n",
      "Epoch 58:  98%|█████████▊| 40/41 [00:02<00:00, 16.28it/s, loss=2.03, v_num=1.57e+7]\n",
      "Epoch 58: 100%|██████████| 41/41 [00:02<00:00, 16.21it/s, loss=2.03, v_num=1.57e+7]\n",
      "Epoch 58: 100%|██████████| 41/41 [00:02<00:00, 16.20it/s, loss=2.03, v_num=1.57e+7]"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm.setup()\n",
    "# model = model.cpu()\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-MSPretraining]",
   "language": "python",
   "name": "conda-env-.conda-MSPretraining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
